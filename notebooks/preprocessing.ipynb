{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04e3fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27712888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set -> Counter({(800, 540): 1405, (800, 542): 8, (783, 541): 2, (738, 541): 2, (797, 541): 2, (780, 544): 2, (788, 545): 2, (796, 542): 2, (782, 542): 2, (790, 539): 2, (796, 544): 2, (780, 539): 2, (789, 540): 2, (798, 541): 1, (799, 563): 1, (789, 545): 1, (791, 544): 1, (794, 544): 1, (783, 543): 1, (786, 542): 1, (794, 543): 1})\n",
      "Test set -> Counter({(800, 540): 295, (800, 542): 2, (799, 563): 1, (789, 545): 1, (791, 544): 1})\n",
      "Valid set -> Counter({(800, 540): 250, (786, 542): 1, (798, 541): 1, (794, 543): 1, (794, 544): 1, (783, 543): 1})\n"
     ]
    }
   ],
   "source": [
    "# Verifies whether resizing or padding is required\n",
    "\n",
    "folder = \"/Users/sasha/Documents/fetal-tumor-segmentation/data/raw/train\"  \n",
    "image_sizes = []\n",
    "\n",
    "for filename in os.listdir(folder):     # os.listdir(folder) returns a list of all the file names inside folder\n",
    "\n",
    "    if filename.lower().endswith((\".png\")):\n",
    "\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        with Image.open(file_path) as image:     # Ensures the image file is automatically closed after use\n",
    "            image_sizes.append(image.size)     # (width, height)\n",
    "            \n",
    "size_frequency = Counter(image_sizes)     # (width, height) to frequency mapping for every unique size\n",
    "print(\"Train set ->\", size_frequency)\n",
    "\n",
    "folder = \"/Users/sasha/Documents/fetal-tumor-segmentation/data/raw/test\"\n",
    "image_sizes = []\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "\n",
    "    if filename.lower().endswith((\".png\")):\n",
    "\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        with Image.open(file_path) as image:\n",
    "            image_sizes.append(image.size)\n",
    "            \n",
    "size_frequency = Counter(image_sizes)\n",
    "print(\"Test set ->\", size_frequency)\n",
    "\n",
    "folder = \"/Users/sasha/Documents/fetal-tumor-segmentation/data/raw/valid\"\n",
    "image_sizes = []\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "\n",
    "    if filename.lower().endswith((\".png\")):\n",
    "\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        with Image.open(file_path) as image:\n",
    "            image_sizes.append(image.size)\n",
    "            \n",
    "size_frequency = Counter(image_sizes)\n",
    "print(\"Valid set ->\", size_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12778ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Users/sasha/Documents/fetal-tumor-segmentation\"     # Projet directory\n",
    "\n",
    "data_dir = os.path.join(root, \"data\")\n",
    "\n",
    "raw_dirs = [\n",
    "    \"/Users/sasha/Documents/fetal-tumor-segmentation/data/raw/train\",\n",
    "    \"/Users/sasha/Documents/fetal-tumor-segmentation/data/raw/test\",\n",
    "    \"/Users/sasha/Documents/fetal-tumor-segmentation/data/raw/valid\"\n",
    "]\n",
    "\n",
    "normalized_dir = os.path.join(data_dir, \"normalized\")\n",
    "norm_img_dir = os.path.join(normalized_dir, \"images\")\n",
    "norm_mask_dir = os.path.join(normalized_dir, \"masks\")\n",
    "\n",
    "final_dir = os.path.join(data_dir, \"dataset\")\n",
    "\n",
    "# Target image resolution\n",
    "target_w = 800\n",
    "target_h = 544\n",
    "mask_suffix = \"_Annotation.png\"     # Suffix used to identify segmentation mask files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "150195e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir(path):\n",
    "\n",
    "    os.makedirs(path, exist_ok=True)     # Create directory (safe if it already exists)\n",
    "\n",
    "def crop_or_pad(pil_img, target_w, target_h):\n",
    "    # Resize an image to the target size by center-cropping or zero-padding\n",
    "\n",
    "    w, h = pil_img.size     # Current image width and height\n",
    "\n",
    "    if w > target_w:     # Center-crop horizontally\n",
    "        left = (w - target_w) // 2\n",
    "        pil_img = pil_img.crop((left, 0, left + target_w, h))\n",
    "        w = target_w\n",
    "\n",
    "    if h > target_h:     # Center-crop vertically\n",
    "        top = (h - target_h) // 2\n",
    "        pil_img = pil_img.crop((0, top, w, top + target_h))\n",
    "        h = target_h\n",
    "\n",
    "    # Compute required padding\n",
    "    pad_w = target_w - w\n",
    "    pad_h = target_h - h\n",
    "\n",
    "    # Apply symmetric zero-padding\n",
    "    if pad_w > 0 or pad_h > 0:\n",
    "        left = pad_w // 2\n",
    "        top  = pad_h // 2\n",
    "        padded = Image.new(\"L\", (target_w, target_h), color=0)\n",
    "        padded.paste(pil_img, (left, top))\n",
    "        pil_img = padded\n",
    "\n",
    "    return pil_img     # Return padded image\n",
    "\n",
    "def normalize():\n",
    "\n",
    "    \"\"\"\n",
    "    Normalize raw images and masks:\n",
    "    - Match image-mask pairs using filename prefixes\n",
    "    - Ensure size consistency\n",
    "    - Crop or pad to a fixed resolution\n",
    "    - Save processed outputs to normalized directories\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create output directories\n",
    "    make_dir(norm_img_dir)\n",
    "    make_dir(norm_mask_dir)\n",
    "\n",
    "    # Track prefixes that do not yet have both image and mask\n",
    "    unresolved = set()\n",
    "\n",
    "    # File-name (prefix) to path mapping\n",
    "    seen_images = {}\n",
    "    seen_masks = {}\n",
    "\n",
    "    for root in raw_dirs:\n",
    "\n",
    "        for fname in os.listdir(root):\n",
    "\n",
    "            prefix = fname.replace(mask_suffix, \"\").replace(\".png\", \"\")     # Extract prefix by removing mask suffix and extension\n",
    "            path = os.path.join(root, fname)\n",
    "\n",
    "            # Categorize file as image or mask\n",
    "            if fname.endswith(mask_suffix):\n",
    "                seen_masks[prefix] = path\n",
    "            else:\n",
    "                seen_images[prefix] = path\n",
    "\n",
    "            # Process both image and mask (if both available)\n",
    "            if prefix in seen_images and prefix in seen_masks:\n",
    "\n",
    "                # Convert image to grayscale\n",
    "                img = Image.open(seen_images[prefix]).convert(\"L\")     # \"L\" = Luminance (1 channel, 8-bit)\n",
    "                mask = Image.open(seen_masks[prefix]).convert(\"L\")\n",
    "\n",
    "                if img.size != mask.size:     # Raise error if size doesn't match\n",
    "                    raise ValueError(f\"Shape mismatch: {prefix}\")\n",
    "\n",
    "                # Crop or pad\n",
    "                img_final  = crop_or_pad(img, target_w, target_h)\n",
    "                mask_final = crop_or_pad(mask, target_w, target_h)\n",
    "\n",
    "                # Save \n",
    "                img_final.save(os.path.join(norm_img_dir, prefix + \".png\"))\n",
    "                mask_final.save(os.path.join(norm_mask_dir, prefix + mask_suffix))\n",
    "\n",
    "                # Pair resolved\n",
    "                unresolved.discard(prefix)\n",
    "\n",
    "            else:\n",
    "\n",
    "                unresolved.add(prefix)\n",
    "\n",
    "    # Print any unmatched imageâ€“mask pairs (should be empty)\n",
    "    print(\"Unresolved prefixes:\", unresolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a806549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unresolved prefixes: set()\n"
     ]
    }
   ],
   "source": [
    "normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5697ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images (norm) -> Counter({(800, 544): 999})\n",
      "Masks (norm) -> Counter({(800, 544): 999})\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: veriify that all normalized images are 800x544\n",
    "\n",
    "folder = \"/Users/sasha/Documents/fetal-tumor-segmentation/data/normalized/images\"\n",
    "image_sizes = []\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "\n",
    "    if filename.lower().endswith((\".png\")):\n",
    "\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        with Image.open(file_path) as image:\n",
    "            image_sizes.append(image.size)\n",
    "            \n",
    "size_frequency = Counter(image_sizes)\n",
    "print(\"Images (norm) ->\", size_frequency)\n",
    "\n",
    "folder = \"/Users/sasha/Documents/fetal-tumor-segmentation/data/normalized/masks\"\n",
    "image_sizes = []\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "\n",
    "    if filename.lower().endswith((\".png\")):\n",
    "\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        with Image.open(file_path) as image:\n",
    "            image_sizes.append(image.size)\n",
    "            \n",
    "size_frequency = Counter(image_sizes)\n",
    "print(\"Masks (norm) ->\", size_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b968ea9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing images: set()\n",
      "Missing masks: set()\n"
     ]
    }
   ],
   "source": [
    "# All normalized image and mask file name\n",
    "imgs = set(os.listdir(norm_img_dir))\n",
    "masks = set(os.listdir(norm_mask_dir))\n",
    "\n",
    "# Extract file-name prefixes from images and masks\n",
    "# Images: remove \".png\"\n",
    "# Masks : remove the mask suffix (e.g., \"_Annotation.png\")\n",
    "img_prefixes  = {f.replace(\".png\", \"\") for f in imgs}\n",
    "mask_prefixes = {f.replace(mask_suffix, \"\") for f in masks}\n",
    "\n",
    "# Set difference\n",
    "print(\"Missing images:\", mask_prefixes - img_prefixes)\n",
    "print(\"Missing masks:\", img_prefixes - mask_prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c801f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)     # Set seed for reproducibility\n",
    "\n",
    "# Proportions\n",
    "splits = {\n",
    "    \"train\": 0.8,\n",
    "    \"valid\": 0.1,\n",
    "    \"test\":  0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17e6d489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset():\n",
    "\n",
    "    prefixes = [f.replace(\".png\", \"\") for f in os.listdir(norm_img_dir)]     # Extract the prefixes\n",
    "\n",
    "    random.shuffle(prefixes)     # Randomly shuffle prefixes to ensure unbiased splitting\n",
    "\n",
    "    n = len(prefixes)     # Number of samples\n",
    "    \n",
    "    t1 = int(n * splits[\"train\"])     # End index of training set\n",
    "    t2 = t1 + int(n * splits[\"valid\"])\n",
    "\n",
    "    # Split name to list of sample IDs mapping\n",
    "    split_map = {\n",
    "        \"train\": prefixes[:t1],\n",
    "        \"valid\": prefixes[t1:t2],\n",
    "        \"test\":  prefixes[t2:]\n",
    "    }\n",
    "\n",
    "    for split, sample_ids in split_map.items():\n",
    "\n",
    "        # Output directories\n",
    "        img_out  = os.path.join(final_dir, split, \"images\")\n",
    "        mask_out = os.path.join(final_dir, split, \"masks\")\n",
    "\n",
    "        make_dir(img_out)\n",
    "        make_dir(mask_out)\n",
    "\n",
    "        for sample_id in sample_ids:\n",
    "\n",
    "            # Copy image \n",
    "            shutil.copy(\n",
    "                os.path.join(norm_img_dir, sample_id + \".png\"),\n",
    "                os.path.join(img_out, sample_id + \".png\")\n",
    "            )\n",
    "\n",
    "            # Copy mask\n",
    "            shutil.copy(\n",
    "                os.path.join(norm_mask_dir, sample_id + mask_suffix),\n",
    "                os.path.join(mask_out, sample_id + mask_suffix)\n",
    "            )\n",
    "\n",
    "    print(\"Split completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24648380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split completed.\n"
     ]
    }
   ],
   "source": [
    "split_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cc7443e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (imgs) set -> Counter({(800, 544): 799})\n",
      "Train (masks) set -> Counter({(800, 544): 799})\n",
      "Test (imgs) set -> Counter({(800, 544): 101})\n",
      "Test (masks) set -> Counter({(800, 544): 101})\n",
      "Valid (imgs) set -> Counter({(800, 544): 99})\n",
      "Valid (masks) set -> Counter({(800, 544): 99})\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "dataset_dirs = {\n",
    "    \"Train (imgs)\": \"/Users/sasha/Documents/fetal-tumor-segmentation/data/dataset/train/images\",\n",
    "    \"Train (masks)\": \"/Users/sasha/Documents/fetal-tumor-segmentation/data/dataset/train/masks\",\n",
    "    \"Test (imgs)\":  \"/Users/sasha/Documents/fetal-tumor-segmentation/data/dataset/test/images\",\n",
    "    \"Test (masks)\":  \"/Users/sasha/Documents/fetal-tumor-segmentation/data/dataset/test/masks\",\n",
    "    \"Valid (imgs)\": \"/Users/sasha/Documents/fetal-tumor-segmentation/data/dataset/valid/images\",\n",
    "    \"Valid (masks)\": \"/Users/sasha/Documents/fetal-tumor-segmentation/data/dataset/valid/masks\",\n",
    "}\n",
    "\n",
    "for split_name, folder in dataset_dirs.items():\n",
    "    image_sizes = []\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.lower().endswith(\".png\"):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            with Image.open(file_path) as image:\n",
    "                image_sizes.append(image.size)\n",
    "\n",
    "    size_frequency = Counter(image_sizes)\n",
    "\n",
    "    print(f\"{split_name} set -> {size_frequency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2afeba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected image shape in NumPy array format: (height, width)\n",
    "# PIL returns image size in (width, height) format,\n",
    "# Since images are 800x544 in PIL, the expected NumPy shape is (544, 800) \n",
    "expected_shape = (544, 800)\n",
    "\n",
    "img_ext = \".png\"\n",
    "mask_ext = \".png\"\n",
    "\n",
    "dataset_dirs = {\n",
    "    \"train\": {\n",
    "        \"images\": \"/Users/sasha/Documents/fetal-tumor-segmentation/data/dataset/train/images\",\n",
    "        \"masks\":  \"/Users/sasha/Documents/fetal-tumor-segmentation/data/dataset/train/masks\",\n",
    "    },\n",
    "    \"valid\": {\n",
    "        \"images\": \"/Users/sasha/Documents/fetal-tumor-segmentation/data/dataset/valid/images\",\n",
    "        \"masks\":  \"/Users/sasha/Documents/fetal-tumor-segmentation/data/dataset/valid/masks\",\n",
    "    },\n",
    "    \"test\": {\n",
    "        \"images\": \"/Users/sasha/Documents/fetal-tumor-segmentation/data/dataset/test/images\",\n",
    "        \"masks\":  \"/Users/sasha/Documents/fetal-tumor-segmentation/data/dataset/test/masks\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e87e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_grayscale(path):\n",
    "\n",
    "    img = Image.open(path).convert(\"L\")\n",
    "    return np.array(img)     # Convert PIL image to a NumPy array\n",
    "\n",
    "def normalize_image(img):\n",
    "\n",
    "    return img.astype(np.float32) / 255.0     # Convert to float and scale pixel intensities to [0, 1]\n",
    "\n",
    "def binarize_mask(mask):     # Binarize mask by treating all non-zero pixels as foreground (1)\n",
    "\n",
    "    return (mask > 0).astype(np.uint8)     # uint8 = unsigned 8-bit integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfb9b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_split(split_name, img_dir, mask_dir):\n",
    "\n",
    "    print(\"Verifying split:\", split_name)\n",
    "\n",
    "    # Collect image and mask filenames\n",
    "    img_files = sorted([f for f in os.listdir(img_dir) if f.endswith(img_ext)])\n",
    "    mask_files = set([f for f in os.listdir(mask_dir) if f.endswith(mask_ext)])\n",
    "\n",
    "    print(\"Images:\", len(img_files))\n",
    "    print(\"Masks :\", len(mask_files))\n",
    "\n",
    "    # Containers to track data issues\n",
    "    empty_masks = []     # Masks with no foreground pixels\n",
    "    border_centroids = []     # Masks whose centroid lies near image borders\n",
    "    intensity_diffs = []     # Intensity contrast between tumor and background\n",
    "\n",
    "    for i, img_name in enumerate(img_files):\n",
    "\n",
    "        base_name = img_name.replace(img_ext, \"\")\n",
    "        expected_mask_name = base_name + \"_Annotation\" + mask_ext\n",
    "\n",
    "        if expected_mask_name not in mask_files:\n",
    "            print(\"Missing mask for image:\", img_name)\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(img_dir, img_name)\n",
    "        mask_path = os.path.join(mask_dir, expected_mask_name)\n",
    "\n",
    "        img = load_grayscale(img_path)\n",
    "        mask = load_grayscale(mask_path)\n",
    "\n",
    "        if img.shape != expected_shape:\n",
    "            print(\"Image shape mismatch:\", img_name, img.shape)\n",
    "            continue\n",
    "\n",
    "        if mask.shape != expected_shape:\n",
    "            print(\"Mask shape mismatch:\", expected_mask_name, mask.shape)\n",
    "            continue\n",
    "\n",
    "        img = normalize_image(img)\n",
    "        mask = binarize_mask(mask)\n",
    "\n",
    "        # Check for empty masks (no foreground pixels)\n",
    "        if mask.sum() == 0:\n",
    "            empty_masks.append(img_name)\n",
    "            continue\n",
    "\n",
    "        # Compute centroid of the tumor region\n",
    "        ys, xs = np.where(mask == 1)     # Returns coordinates of all foreground pixels\n",
    "        cy, cx = ys.mean(), xs.mean()     # Center of mass of the tumor\n",
    "\n",
    "        h, w = mask.shape\n",
    "        if cy < 0.05 * h or cy > 0.95 * h or cx < 0.05 * w or cx > 0.95 * w:     # 0.05h <= cy <= 0.95h and 0.05w <= cx <= 0.95w\n",
    "            border_centroids.append(img_name)\n",
    "\n",
    "        # Use the mask to select regions in the ultrasound image, extract the pixel intensities from those regions, \n",
    "        # and then compute their mean values\n",
    "        tumor_pixels = img[mask == 1]\n",
    "        bg_pixels = img[mask == 0]\n",
    "\n",
    "        if tumor_pixels.size > 0 and bg_pixels.size > 0:\n",
    "            intensity_diffs.append(abs(tumor_pixels.mean() - bg_pixels.mean()))\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\"Checked\", i + 1, \"samples\")\n",
    "\n",
    "    print(\"Summary:\")\n",
    "    print(\"Total samples     :\", len(img_files))\n",
    "    print(\"Empty masks       :\", len(empty_masks))\n",
    "    print(\"Border centroids  :\", len(border_centroids))\n",
    "\n",
    "    if intensity_diffs:\n",
    "        print(\"Mean intensity diff:\", round(np.mean(intensity_diffs), 4))\n",
    "        print()\n",
    "    else:\n",
    "        print(\"Mean intensity diff: n/a\")\n",
    "\n",
    "    return img_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "322dcdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying split: train\n",
      "Images: 799\n",
      "Masks : 799\n",
      "Checked 100 samples\n",
      "Checked 200 samples\n",
      "Checked 300 samples\n",
      "Checked 400 samples\n",
      "Checked 500 samples\n",
      "Checked 600 samples\n",
      "Checked 700 samples\n",
      "Summary:\n",
      "Total samples     : 799\n",
      "Empty masks       : 0\n",
      "Border centroids  : 0\n",
      "Mean intensity diff: 0.2253\n",
      "\n",
      "Verifying split: valid\n",
      "Images: 99\n",
      "Masks : 99\n",
      "Summary:\n",
      "Total samples     : 99\n",
      "Empty masks       : 0\n",
      "Border centroids  : 0\n",
      "Mean intensity diff: 0.21\n",
      "\n",
      "Verifying split: test\n",
      "Images: 101\n",
      "Masks : 101\n",
      "Checked 100 samples\n",
      "Summary:\n",
      "Total samples     : 101\n",
      "Empty masks       : 0\n",
      "Border centroids  : 0\n",
      "Mean intensity diff: 0.2219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split to file mapping\n",
    "split_files = {}\n",
    "\n",
    "for split_name in dataset_dirs:\n",
    "\n",
    "    paths = dataset_dirs[split_name]\n",
    "    img_files = verify_split(\n",
    "        split_name,\n",
    "        paths[\"images\"],\n",
    "        paths[\"masks\"]\n",
    "    )\n",
    "    \n",
    "    split_files[split_name] = img_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6d0964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
